{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络\n",
    "\n",
    "## 简介\n",
    "\n",
    "卷积神经网络结构示意图\n",
    "\n",
    "![卷积神经网络结构示意图](imgs/cnnNet.png)\n",
    "\n",
    "全连接层的参数过多，需要使用卷积神经网络来减少神经网络的参数。\n",
    "![cnnNet2.png](imgs/cnnNet2.png)\n",
    "\n",
    "- 输入层\n",
    "    - 像素矩阵\n",
    "- 卷积层\n",
    "    - 卷积层中每一个节点 的输入只是上一层神经 网络的一小块\n",
    "- 池化层\n",
    "    - 池化层神经网络不会改变三维矩阵的深度\n",
    "    - 缩小矩阵的大小\n",
    "- 全连接层\n",
    "    - 个全连接层来给出最后的分类结果\n",
    "-  Softmax 层\n",
    "\n",
    "卷积计算公式：\n",
    "\n",
    "$H_{out} = (H-F+2 * P)/S + 1$\n",
    "\n",
    "- H：图片高度；\n",
    "- W：图片宽度；\n",
    "- D：原始图片通道数，也是卷积核个数；\n",
    "- F：卷积核高宽大小；\n",
    "- P：图像边扩充大小；\n",
    "- S：滑动步长。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet - 5 模型\n",
    "\n",
    " Yann LeCun 教授于 1998 年在论文 Gradient“based learning  applied  to document  recognitionr中提出的，它是第一个成功应用于数字识别问题的卷积神经网络。\n",
    " LeNet-5 模型总共有 7 层\n",
    " \n",
    " ![LenNet5.png](imgs/LenNet5.png)\n",
    " \n",
    " 2、C1层-卷积层\n",
    "输入图片：32*32\n",
    "\n",
    "卷积核大小：5*5\n",
    "\n",
    "卷积核种类：6\n",
    "\n",
    "输出featuremap大小：28*28 （32-5+1）=28\n",
    "\n",
    "神经元数量：28*28*6\n",
    "\n",
    "可训练参数：（5*5+1) * 6（每个滤波器5*5=25个unit参数和一个bias参数，一共6个滤波器）\n",
    "\n",
    "连接数：（5*5+1）*6*28*28=122304\n",
    "\n",
    "3、S2层-池化层（下采样层）\n",
    "输入：28*28\n",
    "\n",
    "采样区域：2*2\n",
    "\n",
    "采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid\n",
    "\n",
    "采样种类：6\n",
    "\n",
    "输出featureMap大小：14*14（28/2）\n",
    "\n",
    "神经元数量：14*14*6\n",
    "\n",
    "连接数：（2*2+1）*6*14*14\n",
    "\n",
    "S2中每个特征图的大小是C1中特征图大小的1/4。\n",
    " \n",
    " \n",
    "\n",
    "4、C3层-卷积层\n",
    "输入：S2中所有6个或者几个特征map组合\n",
    "\n",
    "卷积核大小：5*5\n",
    "\n",
    "卷积核种类：16\n",
    "\n",
    "输出featureMap大小：10*10 (14-5+1)=10\n",
    "\n",
    "C3中的每个特征map是连接到S2中的所有6个或者几个特征map的，表示本层的特征map是上一层提取到的特征map的不同组合\n",
    "\n",
    "存在的一个方式是：C3的前6个特征图以S2中3个相邻的特征图子集为输入。接下来6个特征图以S2中4个相邻特征图子集为输入。然后的3个以不相邻的4个特征图子集为输入。最后一个将S2中所有特征图为输入。\n",
    "\n",
    "则：可训练参数：6*(3*5*5+1)+6*(4*5*5+1)+3*(4*5*5+1)+1*(6*5*5+1)=1516\n",
    "\n",
    "连接数：10*10*1516=151600\n",
    "\n",
    "\n",
    "5、S4层-池化层（下采样层）\n",
    "输入：10*10\n",
    "\n",
    "采样区域：2*2\n",
    "\n",
    "采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid\n",
    "\n",
    "采样种类：16\n",
    "\n",
    "输出featureMap大小：5*5（10/2）\n",
    "\n",
    "神经元数量：5*5*16=400\n",
    "\n",
    "连接数：16*（2*2+1）*5*5=2000\n",
    "\n",
    "S4中每个特征图的大小是C3中特征图大小的1/4\n",
    "\n",
    "6、C5层-卷积层/全连接层。\n",
    "输入：S4层的全部16个单元特征map（与s4全相连）\n",
    "\n",
    "卷积核大小：5*5\n",
    "\n",
    "卷积核种类：120\n",
    "\n",
    "输出featureMap大小：1*1（5-5+1）\n",
    "\n",
    "可训练参数/连接：120*（16*5*5+1）=48120\n",
    "\n",
    "7、F6层-全连接层\n",
    "输入：c5 120维向量\n",
    "\n",
    "计算方式：计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过sigmoid函数输出。\n",
    "\n",
    "可训练参数:84*(120+1)=10164\n",
    "\n",
    "8、Output层-全连接层\n",
    "Output层也是全连接层，共有10个节点，分别代表数字0到9，且如果节点i的值为0，则网络识别的结果是数字i。采用的是径向基函数（RBF）的网络连接方式。假设x是上一层的输入，y是RBF的输出，则RBF输出的计算方式是：\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
