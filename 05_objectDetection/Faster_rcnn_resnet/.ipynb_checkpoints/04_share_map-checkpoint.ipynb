{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as KL\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_block(filters,block):\n",
    "    \n",
    "    if block != 0:\n",
    "        stride = 1\n",
    "    else:\n",
    "        stride = 2\n",
    "        \n",
    "    def f(x):\n",
    "        \n",
    "        #主通路的网络结构\n",
    "        y = KL.Conv2D(filters=filters,kernel_size=(1,1),strides=stride)(x)\n",
    "        y = KL.BatchNormalization(axis=3)(y)\n",
    "        y = KL.Activation('relu')(y)\n",
    "        \n",
    "        y = KL.Conv2D(filters=filters,kernel_size=(3,3),padding='same')(y)\n",
    "        y = KL.BatchNormalization(axis=3)(y)\n",
    "        y = KL.Activation('relu')(y)\n",
    "        \n",
    "        #主通路的输出\n",
    "        y = KL.Conv2D(filters=4*filters,kernel_size=(1,1))(y)\n",
    "        y = KL.BatchNormalization(axis=3)(y)\n",
    "        \n",
    "        #判断block的类型\n",
    "        if block == 0:\n",
    "            shortcut = KL.Conv2D(filters = 4*filters,kernel_size=(1,1),strides=stride)(x)\n",
    "            shortcut = KL.BatchNormalization(axis=3)(shortcut)\n",
    "        else:\n",
    "            shortcut = x\n",
    "            \n",
    "        #主通路与shortcut 相加     \n",
    "        y = KL.Add()([y,shortcut])\n",
    "        import random\n",
    "        y = KL.Activation('relu',name='last'+ str((random.randint(100,300))))(y)\n",
    "        #y = KL.Activation('relu')(y)\n",
    "        \n",
    "        return y\n",
    "    return f\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet_Extractor(inputs):\n",
    "    \n",
    "    # reanet 预处理 heading\n",
    "    x = KL.Conv2D(filters=64,kernel_size=(3,3),padding='same')(inputs)\n",
    "    x = KL.BatchNormalization(axis=3)(x)\n",
    "    x = KL.Activation('relu')(x)\n",
    "    \n",
    "    filters = 64\n",
    "    \n",
    "    block=[2,2,2]\n",
    "    for i,block_num in enumerate(block):\n",
    "        for block_id in range(block_num):\n",
    "            x = building_block(filters=filters,block=block_id)(x)\n",
    "        filters *=2\n",
    "        \n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RpnNet(inputs,k=9):\n",
    "    \n",
    "    #共享层输出\n",
    "    shareMap = KL.Conv2D(filters=256,kernel_size=(3,3),padding='same',name='sharemap')(inputs)\n",
    "    shareMap = KL.Activation('linear')(shareMap)  #使用linear\n",
    "    \n",
    "    #RPN 分类 前后景\n",
    "    rpn_classfication = KL.Conv2D(filters=2*k,kernel_size=(1,1))(shareMap)\n",
    "    # 为了保证与原始分类输入一致，所以需要reshape\n",
    "    rpn_classfication = KL.Lambda(lambda x:tf.reshape(x,[tf.shape(x)[0],-1,2]))(rpn_classfication)\n",
    "    rpn_classfication = KL.Activation('linear',name='rpn_classfication')(rpn_classfication)\n",
    "    \n",
    "    rpn_probability = KL.Activation('softmax',name='rpn_prob')(rpn_classfication)\n",
    "    \n",
    "    # 计算回归修正\n",
    "    rpn_position = KL.Conv2D(filters=4*k,kernel_size=(1,1))(shareMap)\n",
    "    rpn_position = KL.Activation('linear')(rpn_position)\n",
    "    # -l 表示anchor数量不确定\n",
    "    rpn_BoundingBox = KL.Lambda(lambda x:tf.reshape(x,[tf.shape(x)[0],-1,4]),name='rpn_POS')(rpn_position)\n",
    "    \n",
    "    return rpn_classfication,rpn_probability,rpn_BoundingBox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = KL.Input((64,64,3))\n",
    "featureMap = ResNet_Extractor(x)\n",
    "rpn_classfication,rpn_probability,rpn_BoundingBox = RpnNet(featureMap,k=9)\n",
    "model = Model(inputs=[x],outputs=[rpn_classfication,rpn_probability,rpn_BoundingBox])\n",
    "plot_model(model=model,to_file='sharemap-64.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPNClassLoss(rpn_match,rpn_Cal):\n",
    "    rpn_match = tf.squeeze(rpn_match,axis=-1)\n",
    "    indices = tf.where(K.not_equal(x=rpn_match,y=0))\n",
    "    #1=1,0,-1 = 0\n",
    "    anchor_class = K.cast(K.equal(rpn_match,1),tf.int32)\n",
    "    \n",
    "    # 原始样本结果\n",
    "    anchor_class = tf.gather_nd(params=anchor_class, indices=indices)\n",
    "    #这个是rpn计算结果\n",
    "    rpn_cal_class = tf.gather_nd(params=rpn_Cal,indices=indices)\n",
    "    \n",
    "    # one hot \n",
    "    loss = K.sparse_categorical_crossentropy(target=anchor_class,output=rpn_cal_class,\n",
    "                                            from_logits=True)\n",
    "    \n",
    "    loss = K.switch(condition=tf.size(loss)>0,then_expression=K.mean(loss),else_expression=tf.constant(0.0))\n",
    "    \n",
    "    return loss\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
